{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/edaaydinea/deep-learning-with-pytorch-siamese-network?scriptVersionId=123511218\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Deep Learning with PyTorch : Siamese Network\n\n*Author: Eda AYDIN*","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Siamese Network\n\n![siamese-network.png](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bJABur9wzFNACosQkim8kw.png)\n\n[Eng]\n\nA Siamese Network is a type of neural network architecture that is used for tasks that involve finding similarities or differences between two input samples. The network consists of two identical subnetworks that share the same set of weights and are trained simultaneously.\n\nThe basic idea behind a Siamese Network is to learn a similarity metric between two input samples. In other words, the network is trained to output a high value when the two input samples are similar and a low value when they are dissimilar. This makes it useful for a variety of applications, such as image or text similarity matching, face recognition, and signature verification.\n\nOne of main advantages of a Siamese Network is that it can be trained with very few examples, making it useful for applications where data is limited. Additionally, the shared weights between the two subnetworks allow the model to generalize well to new inputs.\n\nSiamese Networks have been shown to be effective in a wide range of applications, including image recognition, classification, and speech recognition. They have also been applied to natural language processing tasks such as sentence similarity and paraphrase detection.\n\n\n[Tr]\n\nSiamese Network, iki giriş örneği arasındaki benzerlik ve farklılıkları bulmak için kullanılan bir sinir ağı mimarisidir. Ağ, iki aynı alt ağdan oluşur ve her biri aynı ağırlık kümesini paylaşır.\n\nSiamese Network'ün temel fikri, iki giriş örneği arasındaki benzerliği öğrenmektir. Bu nedenle, ağ, iki giriş örneği benzer olduğunda yüksek bir çıktı değeri verir ve farklı olduğunda ise düşük bir çıktı değeri verir. Bu, örneğin görüntü veya metin benzerliği eşleştirme, yüz tanıma veya imza doğrulama gibi birçok uygulama için kullanışlıdır.\n\nSiamese Network'ü kullanmanın en büyük avantajı, sınırlı veriyle bile eğitilebilmesidir. Ayrıca, alt ağlar arasındaki ağırlık paylaşımı, modelin yeni girişlere iyi genelleme yapabilmesine olanak tanır.\n\nSiamese Network, görüntü tanıma, sınıflandırma ve konuşma tanıma gibi birçok alanda etkili olduğu kanıtlanmıştır. Ayrıca, cümle benzerliği ve paraphrase tespiti gibi doğal dil işleme görevleri için de uygulanabilir.","metadata":{}},{"cell_type":"markdown","source":"# Download and Import libraries","metadata":{}},{"cell_type":"code","source":"!pip instaLWP:Sll segmentation-models-pytorch -q\n!pip install -U git+https://github.com/albumentations-team/albumentations -q\n!pip install --upgrade opencv-contrib-python -q","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:22:54.603594Z","iopub.execute_input":"2023-03-16T22:22:54.604431Z","iopub.status.idle":"2023-03-16T22:23:22.358365Z","shell.execute_reply.started":"2023-03-16T22:22:54.604202Z","shell.execute_reply":"2023-03-16T22:23:22.357032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/parth1620/Person-Re-Id-Dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:22.360827Z","iopub.execute_input":"2023-03-16T22:23:22.361286Z","iopub.status.idle":"2023-03-16T22:23:25.805717Z","shell.execute_reply.started":"2023-03-16T22:23:22.361241Z","shell.execute_reply":"2023-03-16T22:23:25.804557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/Person-Re-Id-Dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:25.808454Z","iopub.execute_input":"2023-03-16T22:23:25.808847Z","iopub.status.idle":"2023-03-16T22:23:25.814465Z","shell.execute_reply.started":"2023-03-16T22:23:25.808805Z","shell.execute_reply":"2023-03-16T22:23:25.813203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\n\n\"\"\"\nTimm: PyTorch Image Models (timm) is a library for state-of-the-art-image classification, containing a collection of image models, optimizers, schedulers, augmentations and much more.\n\"\"\"\nimport timm\n\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom skimage import io\nfrom sklearn.model_selection import train_test_split\n\n\"\"\"\ntqdm is a library that is used for creating Python Progress Bars. It gets its name from the Arabic name taqaddum, which means 'progress. '\n\"\"\"\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:25.81899Z","iopub.execute_input":"2023-03-16T22:23:25.819978Z","iopub.status.idle":"2023-03-16T22:23:28.848305Z","shell.execute_reply.started":"2023-03-16T22:23:25.819935Z","shell.execute_reply":"2023-03-16T22:23:28.847178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/market-1501/Market-1501-v15.09.15/bounding_box_train/\"\nCSV_FILE = \"/kaggle/working/Person-Re-Id-Dataset/train.csv\"\n\nBATCH_SIZE = 32\nLR = 0.001\nEPOCHS = 15\n\nDEVICE = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:28.84992Z","iopub.execute_input":"2023-03-16T22:23:28.850348Z","iopub.status.idle":"2023-03-16T22:23:28.85797Z","shell.execute_reply.started":"2023-03-16T22:23:28.850302Z","shell.execute_reply":"2023-03-16T22:23:28.856592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(CSV_FILE)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:28.859498Z","iopub.execute_input":"2023-03-16T22:23:28.860166Z","iopub.status.idle":"2023-03-16T22:23:29.053065Z","shell.execute_reply.started":"2023-03-16T22:23:28.860119Z","shell.execute_reply":"2023-03-16T22:23:29.051969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = df.iloc[11]\n\n\n\nA_img = io.imread(DATA_DIR + row.Anchor)\nP_img = io.imread(DATA_DIR + row.Positive)\nN_img = io.imread(DATA_DIR + row.Negative)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.054709Z","iopub.execute_input":"2023-03-16T22:23:29.055128Z","iopub.status.idle":"2023-03-16T22:23:29.114458Z","shell.execute_reply.started":"2023-03-16T22:23:29.055089Z","shell.execute_reply":"2023-03-16T22:23:29.113548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (10,5))\n\nax1.set_title(\"Anchor\")\nax1.imshow(A_img)\n\nax2.set_title(\"Positive\")\nax2.imshow(P_img)\n\nax3.set_title(\"Negative\")\nax3.imshow(N_img)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.115724Z","iopub.execute_input":"2023-03-16T22:23:29.116103Z","iopub.status.idle":"2023-03-16T22:23:29.537366Z","shell.execute_reply.started":"2023-03-16T22:23:29.116063Z","shell.execute_reply":"2023-03-16T22:23:29.536307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(df, test_size = 0.20, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.538508Z","iopub.execute_input":"2023-03-16T22:23:29.53888Z","iopub.status.idle":"2023-03-16T22:23:29.548916Z","shell.execute_reply.started":"2023-03-16T22:23:29.538844Z","shell.execute_reply":"2023-03-16T22:23:29.548006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create APN Dataset","metadata":{}},{"cell_type":"code","source":"class APN_Dataset(Dataset):\n    \n    def __init__(self, df):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        row = self.df.iloc[idx]\n        \n        A_img = io.imread(DATA_DIR + row.Anchor)\n        P_img = io.imread(DATA_DIR + row.Positive)\n        N_img = io.imread(DATA_DIR + row.Negative)\n        \n        A_img = torch.from_numpy(A_img).permute(2, 0 ,1) / 255.0\n        P_img = torch.from_numpy(P_img).permute(2, 0 ,1) / 255.0\n        N_img = torch.from_numpy(N_img).permute(2, 0 ,1) / 255.0\n        \n        return A_img, P_img, N_img\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.550625Z","iopub.execute_input":"2023-03-16T22:23:29.551464Z","iopub.status.idle":"2023-03-16T22:23:29.559794Z","shell.execute_reply.started":"2023-03-16T22:23:29.551424Z","shell.execute_reply":"2023-03-16T22:23:29.558894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = APN_Dataset(train_df)\nvalidset = APN_Dataset(valid_df)\n\nprint(f\"Size of trainset : {len(trainset)}\")\nprint(f\"Size of validset : {len(validset)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.56126Z","iopub.execute_input":"2023-03-16T22:23:29.562444Z","iopub.status.idle":"2023-03-16T22:23:29.571168Z","shell.execute_reply.started":"2023-03-16T22:23:29.562406Z","shell.execute_reply":"2023-03-16T22:23:29.570204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 40\nA,P,N = trainset[idx]\n\nf, (ax1, ax2, ax3) = plt.subplots(1,3,figsize= (10,5))\n\nax1.set_title('Anchor')\nax1.imshow(A.numpy().transpose((1,2,0)), cmap = 'gray')\n\nax2.set_title('Positive')\nax2.imshow(P.numpy().transpose((1,2,0)), cmap = 'gray')\n\nax3.set_title('Negative')\nax3.imshow(N.numpy().transpose((1,2,0)), cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:29.572743Z","iopub.execute_input":"2023-03-16T22:23:29.573129Z","iopub.status.idle":"2023-03-16T22:23:30.062066Z","shell.execute_reply.started":"2023-03-16T22:23:29.573092Z","shell.execute_reply":"2023-03-16T22:23:30.060973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset into Batches","metadata":{}},{"cell_type":"code","source":"trainloader = DataLoader(trainset, batch_size = BATCH_SIZE,shuffle = True)\nvalidloader = DataLoader(validset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:30.066493Z","iopub.execute_input":"2023-03-16T22:23:30.06745Z","iopub.status.idle":"2023-03-16T22:23:30.072952Z","shell.execute_reply.started":"2023-03-16T22:23:30.06741Z","shell.execute_reply":"2023-03-16T22:23:30.071763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"No. of batches in trainloader : {len(trainloader)}\")\nprint(f\"No. of batches in validloader : {len(validloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:30.074999Z","iopub.execute_input":"2023-03-16T22:23:30.075467Z","iopub.status.idle":"2023-03-16T22:23:30.085057Z","shell.execute_reply.started":"2023-03-16T22:23:30.075429Z","shell.execute_reply":"2023-03-16T22:23:30.083853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for A, P, N in trainloader:\n    break;\n\nprint(f\"One image batch shape : {A.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:30.086823Z","iopub.execute_input":"2023-03-16T22:23:30.087244Z","iopub.status.idle":"2023-03-16T22:23:31.321891Z","shell.execute_reply.started":"2023-03-16T22:23:30.087207Z","shell.execute_reply":"2023-03-16T22:23:31.32082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"class APN_Model(nn.Module):\n    \n    def __init__(self, emb_size = 512):\n        super(APN_Model, self).__init__()\n        \n        self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n        self.efficientnet.classifier = nn.Linear(in_features = self.efficientnet.classifier.in_features,\n                                                out_features = emb_size)\n        \n    \n    def forward(self, images):\n        embeddings = self.efficientnet(images)\n        return embeddings","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:31.323346Z","iopub.execute_input":"2023-03-16T22:23:31.323816Z","iopub.status.idle":"2023-03-16T22:23:31.331028Z","shell.execute_reply.started":"2023-03-16T22:23:31.323774Z","shell.execute_reply":"2023-03-16T22:23:31.329754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = APN_Model()\nmodel.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:31.332884Z","iopub.execute_input":"2023-03-16T22:23:31.333813Z","iopub.status.idle":"2023-03-16T22:23:35.768155Z","shell.execute_reply.started":"2023-03-16T22:23:31.333774Z","shell.execute_reply":"2023-03-16T22:23:35.767023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Train and Eval Function","metadata":{}},{"cell_type":"code","source":"def train_fn(model, dataloader, optimizer, criterion):\n    model.train() # ON Dropout\n    total_loss = 0.0 \n    \n    for A,P,N in tqdm(dataloader):\n        A,P,N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n        \n        A_embs = model(A)\n        P_embs = model(P)\n        N_embs = model(N)\n        \n        loss = criterion(A_embs, P_embs, N_embs)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:35.769952Z","iopub.execute_input":"2023-03-16T22:23:35.770386Z","iopub.status.idle":"2023-03-16T22:23:35.777832Z","shell.execute_reply.started":"2023-03-16T22:23:35.770338Z","shell.execute_reply":"2023-03-16T22:23:35.776261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(model, dataloader, criterion):\n    model.eval()  # OFF Dropout\n    total_loss = 0.0 \n    \n    with torch.no_grad():\n        for A,P,N in tqdm(dataloader):\n            A,P,N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n\n            A_embs = model(A)\n            P_embs = model(P)\n            N_embs = model(N)\n\n            loss = criterion(A_embs, P_embs, N_embs)\n\n            total_loss += loss.item()\n        \n        return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:35.779328Z","iopub.execute_input":"2023-03-16T22:23:35.779865Z","iopub.status.idle":"2023-03-16T22:23:36.215137Z","shell.execute_reply.started":"2023-03-16T22:23:35.779827Z","shell.execute_reply":"2023-03-16T22:23:36.213873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.TripletMarginLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = LR)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:23:36.216811Z","iopub.execute_input":"2023-03-16T22:23:36.218926Z","iopub.status.idle":"2023-03-16T22:23:36.229147Z","shell.execute_reply.started":"2023-03-16T22:23:36.218894Z","shell.execute_reply":"2023-03-16T22:23:36.228052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Training Loop","metadata":{}},{"cell_type":"code","source":"best_valid_loss = np.Inf\n\nfor i in range(EPOCHS):\n    train_loss = train_fn(model, trainloader, optimizer, criterion)\n    valid_loss = eval_fn(model, validloader, criterion)\n    \n    if valid_loss < best_valid_loss:\n        torch.save(model.state_dict(), \"best_model.pt\")\n        best_valid_loss = valid_loss\n        print(\"SAVED_WEIGHT_SUCCESS\")\n    \n    print(f\"EPOCHS: {i+1} train_loss: {train_loss} valid_loss: {valid_loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:31:19.317642Z","iopub.execute_input":"2023-03-16T22:31:19.318034Z","iopub.status.idle":"2023-03-16T22:38:57.102739Z","shell.execute_reply.started":"2023-03-16T22:31:19.317983Z","shell.execute_reply":"2023-03-16T22:38:57.101665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Get Anchor Embeddings","metadata":{}},{"cell_type":"code","source":"def get_encoding_csv(model, anc_img_names):\n    anc_img_names_arr = np.array(anc_img_names)\n    encodings = []\n    \n    model.eval()\n    with torch.no_grad():\n        for i in tqdm(anc_img_names_arr):\n            A = io.imread(DATA_DIR + i)\n            A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n            A = A. to(DEVICE)\n            A_enc = model(A.unsqueeze(0)) # c,h,w --> (1,c,h,w)\n            encodings.append(A_enc.squeeze().cpu().detach().numpy())\n        \n        encodings = np.array(encodings)\n        encodings = pd.DataFrame(encodings)\n        df_enc = pd.concat([anc_img_names, encodings], axis=1)\n    \n    return df_enc","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:43:45.102411Z","iopub.execute_input":"2023-03-16T22:43:45.102946Z","iopub.status.idle":"2023-03-16T22:43:45.117327Z","shell.execute_reply.started":"2023-03-16T22:43:45.10291Z","shell.execute_reply":"2023-03-16T22:43:45.11604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pt\"))\ndf_enc = get_encoding_csv(model, df[\"Anchor\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:43:47.515115Z","iopub.execute_input":"2023-03-16T22:43:47.515488Z","iopub.status.idle":"2023-03-16T22:44:34.512269Z","shell.execute_reply.started":"2023-03-16T22:43:47.515454Z","shell.execute_reply":"2023-03-16T22:44:34.511283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_enc.to_csv(\"database.csv\", index=False)\ndf_enc.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:44:34.51401Z","iopub.execute_input":"2023-03-16T22:44:34.514344Z","iopub.status.idle":"2023-03-16T22:44:36.165422Z","shell.execute_reply.started":"2023-03-16T22:44:34.514315Z","shell.execute_reply":"2023-03-16T22:44:36.164284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def euclidean_dist(img_enc, anc_enc_arr):\n    dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc - anc_enc_arr).T))\n    return dist","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:44:58.57495Z","iopub.execute_input":"2023-03-16T22:44:58.575563Z","iopub.status.idle":"2023-03-16T22:44:58.585056Z","shell.execute_reply.started":"2023-03-16T22:44:58.575515Z","shell.execute_reply":"2023-03-16T22:44:58.583468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\nimg_name = df_enc[\"Anchor\"].iloc[idx]\nimg_path = DATA_DIR + img_name\n\nimg = io.imread(img_path)\nimg = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n\nmodel.eval()\nwith torch.no_grad():\n    img = img.to(DEVICE)\n    img_enc = model(img.unsqueeze(0))\n    img_enc = img_enc.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:47:22.340107Z","iopub.execute_input":"2023-03-16T22:47:22.340575Z","iopub.status.idle":"2023-03-16T22:47:22.379109Z","shell.execute_reply.started":"2023-03-16T22:47:22.340533Z","shell.execute_reply":"2023-03-16T22:47:22.378067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anc_enc_arr = df_enc.iloc[:, 1:].to_numpy()\nanc_img_names = df_enc[\"Anchor\"]","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:49:41.339367Z","iopub.execute_input":"2023-03-16T22:49:41.339998Z","iopub.status.idle":"2023-03-16T22:49:41.348907Z","shell.execute_reply.started":"2023-03-16T22:49:41.339958Z","shell.execute_reply":"2023-03-16T22:49:41.347531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"distance = []\n\nfor i in range(anc_enc_arr.shape[0]):\n    dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n    distance = np.append(distance, dist)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:49:52.230134Z","iopub.execute_input":"2023-03-16T22:49:52.230522Z","iopub.status.idle":"2023-03-16T22:49:52.28682Z","shell.execute_reply.started":"2023-03-16T22:49:52.230488Z","shell.execute_reply":"2023-03-16T22:49:52.285822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"closest_idx = np.argsort(distance)","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:50:20.254242Z","iopub.execute_input":"2023-03-16T22:50:20.254618Z","iopub.status.idle":"2023-03-16T22:50:20.259774Z","shell.execute_reply.started":"2023-03-16T22:50:20.254585Z","shell.execute_reply":"2023-03-16T22:50:20.258586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils import plot_closest_imgs\n\nplot_closest_imgs(anc_img_names, DATA_DIR, img, img_path, closest_idx, distance, no_of_closest = 10);","metadata":{"execution":{"iopub.status.busy":"2023-03-16T22:50:47.884443Z","iopub.execute_input":"2023-03-16T22:50:47.884824Z","iopub.status.idle":"2023-03-16T22:50:49.031687Z","shell.execute_reply.started":"2023-03-16T22:50:47.88479Z","shell.execute_reply":"2023-03-16T22:50:49.030771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resources\n\n* [How to train your siamese neural network](https://towardsdatascience.com/how-to-train-your-siamese-neural-network-4c6da3259463)","metadata":{}}]}