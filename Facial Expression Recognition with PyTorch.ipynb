{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/edaaydinea/facial-expression-recognition-with-pytorch?scriptVersionId=123511190\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Facial Expression Recognition with PyTorch\n\n*Author: Eda AYDIN*","metadata":{}},{"cell_type":"markdown","source":"# Business Understanding\n\nFacial Expression Recognition is a critical technology that is gaining traction in various industries, including healthcare, entertainment, and security. The goal of this project is to develop an accurate and efficient Facial Expression Recognition model using the PyTorch framework. The model will be trained on a large dataset of facial expressions to recognize different emotions, including happiness, sadness, fear, anger, and surprise. The ultimate objective of this project is to provide businesses with a tool that can improve customer experience, increase security, and enhance overall operational efficiency. For instance, the technology can be used in healthcare to detect early signs of depression or anxiety in patients, in entertainment to enhance gaming experiences, and in security to monitor public spaces for suspicious behavior. The Facial Expression Recognition with PyTorch project has the potential to revolutionize various industries by providing an automated, accurate, and reliable tool for recognizing emotions.","metadata":{}},{"cell_type":"markdown","source":"# Data Understanding\n\nThe Face Expression Recognition dataset available on Kaggle contains 28,709 images of human faces, labeled with seven different facial expressions, including angry, disgust, fear, happy, sad, surprise, and neutral. \n\nThe dataset is split into two subsets, a training set of 24,706 images and a test set of 4,003 images. The images are grayscale, 48Ã—48 pixels in size, and the data is stored in CSV format. Each row of the CSV file corresponds to an image and contains the pixel values of the image, the emotion label, and other attributes, such as the image usage and intensity. \n\nThe dataset is well-balanced, with each emotion class containing approximately the same number of images. It is important to note that the images were extracted from the FER2013 dataset and preprocessed to contain only faces with frontal pose and appropriate brightness, resulting in some loss of information. \n\nAdditionally, the dataset contains some images with low resolution or artifacts, which may affect the performance of the model. \n\nOverall, the Face Expression Recognition dataset provides a diverse and labeled set of images for training and testing facial expression recognition models.","metadata":{}},{"cell_type":"markdown","source":"# Install libraries, packages and dataset","metadata":{}},{"cell_type":"code","source":"!pip install -U git+https://github.com/albumentations-team/albumentations\n!pip install timm\n!pip install --upgrade opencv-contrib-python","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:46:55.7809Z","iopub.execute_input":"2023-03-19T21:46:55.781423Z","iopub.status.idle":"2023-03-19T21:47:30.70243Z","shell.execute_reply.started":"2023-03-19T21:46:55.781379Z","shell.execute_reply":"2023-03-19T21:47:30.701163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:30.704862Z","iopub.execute_input":"2023-03-19T21:47:30.705163Z","iopub.status.idle":"2023-03-19T21:47:33.230595Z","shell.execute_reply.started":"2023-03-19T21:47:30.70513Z","shell.execute_reply":"2023-03-19T21:47:33.229584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":"TRAIN_IMG_FOLDER_PATH = \"/kaggle/input/face-expression-recognition-dataset/images/train\"\nVALID_IMG_FOLDER_PATH = \"/kaggle/input/face-expression-recognition-dataset/images/validation\"\n\nLR = 0.001\nBATCH_SIZE = 32\nEPOCHS = 15\n\nDEVICE = 'cuda'\nMODEL_NAME = 'efficientnet_b0'","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:33.235276Z","iopub.execute_input":"2023-03-19T21:47:33.238136Z","iopub.status.idle":"2023-03-19T21:47:33.245064Z","shell.execute_reply.started":"2023-03-19T21:47:33.238096Z","shell.execute_reply":"2023-03-19T21:47:33.243797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torchvision import transforms as T\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:33.251158Z","iopub.execute_input":"2023-03-19T21:47:33.254007Z","iopub.status.idle":"2023-03-19T21:47:33.480556Z","shell.execute_reply.started":"2023-03-19T21:47:33.253968Z","shell.execute_reply":"2023-03-19T21:47:33.479516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_augs = T.Compose([\n    T.RandomHorizontalFlip(p = 0.5),\n    T.RandomRotation(degrees=(-20, + 20)),\n    T.ToTensor() # Convert a PIL image or numpy.ndarray to tensor (h, w, c) --> (c, h, w)\n])\n\nvalid_augs = T.Compose([\n    T.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:33.482138Z","iopub.execute_input":"2023-03-19T21:47:33.482504Z","iopub.status.idle":"2023-03-19T21:47:33.489118Z","shell.execute_reply.started":"2023-03-19T21:47:33.482459Z","shell.execute_reply":"2023-03-19T21:47:33.487677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform = train_augs)\nvalidset = ImageFolder(VALID_IMG_FOLDER_PATH, transform = valid_augs)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:33.491176Z","iopub.execute_input":"2023-03-19T21:47:33.492165Z","iopub.status.idle":"2023-03-19T21:47:43.089113Z","shell.execute_reply.started":"2023-03-19T21:47:33.492124Z","shell.execute_reply":"2023-03-19T21:47:43.087971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total no. of examples in trainset : {len(trainset)}\")\nprint(f\"Total no. of examples in validset : {len(validset)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.09086Z","iopub.execute_input":"2023-03-19T21:47:43.091615Z","iopub.status.idle":"2023-03-19T21:47:43.097924Z","shell.execute_reply.started":"2023-03-19T21:47:43.09156Z","shell.execute_reply":"2023-03-19T21:47:43.096808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(trainset.class_to_idx)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.09957Z","iopub.execute_input":"2023-03-19T21:47:43.100308Z","iopub.status.idle":"2023-03-19T21:47:43.108813Z","shell.execute_reply.started":"2023-03-19T21:47:43.10027Z","shell.execute_reply":"2023-03-19T21:47:43.107476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = trainset.classes\n\nindex = random.randint(0, len(trainset)-1)\nimage, label = trainset[index]\n\nplt.imshow(image.permute(1, 2, 0)) # (h, w, c)\nplt.title(class_names[label])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.110124Z","iopub.execute_input":"2023-03-19T21:47:43.111176Z","iopub.status.idle":"2023-03-19T21:47:43.401885Z","shell.execute_reply.started":"2023-03-19T21:47:43.111138Z","shell.execute_reply":"2023-03-19T21:47:43.400704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = validset.classes\n\nindex = random.randint(0, len(validset)-1)\nimage, label = validset[index]\n\nplt.imshow(image.permute(1, 2, 0)) # (h, w, c)\nplt.title(class_names[label])","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.406426Z","iopub.execute_input":"2023-03-19T21:47:43.406716Z","iopub.status.idle":"2023-03-19T21:47:43.616998Z","shell.execute_reply.started":"2023-03-19T21:47:43.406687Z","shell.execute_reply":"2023-03-19T21:47:43.61594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset into Batches","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.618659Z","iopub.execute_input":"2023-03-19T21:47:43.619348Z","iopub.status.idle":"2023-03-19T21:47:43.624592Z","shell.execute_reply.started":"2023-03-19T21:47:43.619308Z","shell.execute_reply":"2023-03-19T21:47:43.623251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\nvalidloader = DataLoader(validset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.626063Z","iopub.execute_input":"2023-03-19T21:47:43.626488Z","iopub.status.idle":"2023-03-19T21:47:43.634486Z","shell.execute_reply.started":"2023-03-19T21:47:43.626451Z","shell.execute_reply":"2023-03-19T21:47:43.633769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Total no. of batches in trainloader : {len(trainloader)}\")\nprint(f\"Total no. of batches in validloader : {len(validloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.63614Z","iopub.execute_input":"2023-03-19T21:47:43.636503Z","iopub.status.idle":"2023-03-19T21:47:43.64558Z","shell.execute_reply.started":"2023-03-19T21:47:43.636467Z","shell.execute_reply":"2023-03-19T21:47:43.644467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, labels in trainloader:\n    break;\n\nprint(f\"One image batch shape : {images.shape}\")\nprint(f\"One label batch shape : {labels.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.647568Z","iopub.execute_input":"2023-03-19T21:47:43.648784Z","iopub.status.idle":"2023-03-19T21:47:43.760616Z","shell.execute_reply.started":"2023-03-19T21:47:43.648721Z","shell.execute_reply":"2023-03-19T21:47:43.7595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model ","metadata":{}},{"cell_type":"code","source":"import timm\nfrom torch import nn","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:43.761844Z","iopub.execute_input":"2023-03-19T21:47:43.762185Z","iopub.status.idle":"2023-03-19T21:47:44.557984Z","shell.execute_reply.started":"2023-03-19T21:47:43.76215Z","shell.execute_reply":"2023-03-19T21:47:44.556834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FaceModel(nn.Module):\n    \n    def __init__(self):\n        super(FaceModel, self).__init__()\n        \n        self.eff_net = timm.create_model('efficientnet_b0',\n                                        pretrained = True,\n                                        num_classes = 7)\n        \n    def forward(self, images, labels = None):\n        logits = self.eff_net(images)\n        \n        if labels != None:\n            loss = nn.CrossEntropyLoss()(logits, labels)\n            return logits, loss\n        \n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:44.561014Z","iopub.execute_input":"2023-03-19T21:47:44.56183Z","iopub.status.idle":"2023-03-19T21:47:44.568921Z","shell.execute_reply.started":"2023-03-19T21:47:44.561778Z","shell.execute_reply":"2023-03-19T21:47:44.567698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FaceModel()\nmodel.to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:44.570155Z","iopub.execute_input":"2023-03-19T21:47:44.570439Z","iopub.status.idle":"2023-03-19T21:47:48.440932Z","shell.execute_reply.started":"2023-03-19T21:47:44.570412Z","shell.execute_reply":"2023-03-19T21:47:48.439727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Train and Eval Function","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.442171Z","iopub.execute_input":"2023-03-19T21:47:48.442559Z","iopub.status.idle":"2023-03-19T21:47:48.449818Z","shell.execute_reply.started":"2023-03-19T21:47:48.442521Z","shell.execute_reply":"2023-03-19T21:47:48.448794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiclass_accuracy(y_pred, y_true):\n    top_p, top_class = y_pred.topk(1, dim = 1)\n    equals = top_class = y_true.view(*top_class.shape)\n    return torch.mean(equals.type(torch.FloatTensor))","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.451156Z","iopub.execute_input":"2023-03-19T21:47:48.452178Z","iopub.status.idle":"2023-03-19T21:47:48.466487Z","shell.execute_reply.started":"2023-03-19T21:47:48.452138Z","shell.execute_reply":"2023-03-19T21:47:48.465325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, dataloader, optimizer, current_epo):\n    model.train()\n    total_loss = 0.0\n    total_acc = 0.0\n    tk = tqdm(dataloader, desc = \"EPOCH\" + \"[TRAIN]\" + str(current_epo + 1) + \"/\" + str(EPOCHS))\n    \n    for t, data in enumerate(tk):\n        images, labels = data\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        \n        optimizer.zero_grad()\n        logits, loss = model(images, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_acc += multiclass_accuracy(logits, labels)\n        tk.set_postfix({'loss' : '%6f' %float(total_loss / (t+1)), 'acc' : '%6f' %float(total_acc / (t+1)),})\n        \n    return total_loss / len(dataloader), total_acc / len(dataloader)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.46795Z","iopub.execute_input":"2023-03-19T21:47:48.468605Z","iopub.status.idle":"2023-03-19T21:47:48.478677Z","shell.execute_reply.started":"2023-03-19T21:47:48.468566Z","shell.execute_reply":"2023-03-19T21:47:48.477609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(model, dataloader, current_epo):\n    model.eval()\n    total_loss = 0.0\n    total_acc = 0.0\n    tk = tqdm(dataloader, desc = \"EPOCH\" + \"[TRAIN]\" + str(current_epo + 1) + \"/\" + str(EPOCHS))\n    \n    for t, data in enumerate(tk):\n        images, labels = data\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        \n        logits, loss = model(images, labels)\n        \n        total_loss += loss.item()\n        total_acc += multiclass_accuracy(logits, labels)\n        tk.set_postfix({'loss' : '%6f' %float(total_loss / (t+1)), 'acc' : '%6f' %float(total_acc / (t+1)),})\n        \n    return total_loss / len(dataloader), total_acc / len(dataloader)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.480086Z","iopub.execute_input":"2023-03-19T21:47:48.480813Z","iopub.status.idle":"2023-03-19T21:47:48.489018Z","shell.execute_reply.started":"2023-03-19T21:47:48.480777Z","shell.execute_reply":"2023-03-19T21:47:48.488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Training Loop","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params = model.parameters(),\n                             lr = LR)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.490503Z","iopub.execute_input":"2023-03-19T21:47:48.490895Z","iopub.status.idle":"2023-03-19T21:47:48.502112Z","shell.execute_reply.started":"2023-03-19T21:47:48.490856Z","shell.execute_reply":"2023-03-19T21:47:48.501163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_valid_loss = np.Inf\n\nfor i in range(EPOCHS):\n    train_loss, train_acc = train_fn(model, trainloader, optimizer, i)\n    valid_loss, valid_acc = eval_fn(model, validloader, i)\n    \n    if valid_loss < best_valid_loss:\n        torch.save(model.state_dict(), 'best-weights.pt')\n        print(\"SAVED-BEST-WEIGHTS\")\n        best_valid_loss = valid_loss","metadata":{"execution":{"iopub.status.busy":"2023-03-19T21:47:48.503768Z","iopub.execute_input":"2023-03-19T21:47:48.504188Z","iopub.status.idle":"2023-03-19T22:10:06.630575Z","shell.execute_reply.started":"2023-03-19T21:47:48.504153Z","shell.execute_reply":"2023-03-19T22:10:06.629394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def view_classify(img, ps):\n  \n    classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'suprise']\n    \n    ps = ps.data.cpu().numpy().squeeze()\n    img = img.numpy().transpose(1,2,0)\n    \n    fig, (ax1, ax2) = plt.subplots(figsize = (5,9), ncols = 2)\n    ax1.imshow(img)\n    ax1.axis('off')\n    ax2.barh(classes, ps)\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes)\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Class Probability')\n    ax2.set_xlim(0, 1.1)\n    \n    plt.tight_layout()\n    \n    return None","metadata":{"execution":{"iopub.status.busy":"2023-03-19T22:10:42.392455Z","iopub.execute_input":"2023-03-19T22:10:42.39337Z","iopub.status.idle":"2023-03-19T22:10:42.401066Z","shell.execute_reply.started":"2023-03-19T22:10:42.393319Z","shell.execute_reply":"2023-03-19T22:10:42.399913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, label = validset[97]\nimage = image.unsqueeze(0)\n\nlogits = model(image.to(DEVICE))\nprobs = nn.Softmax(dim=1)(logits)\n\nview_classify(image.squeeze(), probs)","metadata":{"execution":{"iopub.status.busy":"2023-03-19T22:10:43.063474Z","iopub.execute_input":"2023-03-19T22:10:43.063954Z","iopub.status.idle":"2023-03-19T22:10:43.298958Z","shell.execute_reply.started":"2023-03-19T22:10:43.063918Z","shell.execute_reply":"2023-03-19T22:10:43.297711Z"},"trusted":true},"execution_count":null,"outputs":[]}]}